{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Basic_Statistics_Demo_toStudent.ipynb","provenance":[{"file_id":"1i65SEYSRPo5hEiRNDpo848NUldYb2U81","timestamp":1580178813677}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"c5iTN0-9OiHU"},"source":["# OUTLINES\n","\n","Part1: Statistical Analysis\n","\n","Part2: Inferential Statistics\n","\n","Part3: A/B Testing\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gM2uPpV2O-UV"},"source":["# Part1: Statistical Analysis"]},{"cell_type":"markdown","metadata":{"id":"mJEZ0HipOvv-"},"source":["## Introduction to Statistics\n"]},{"cell_type":"code","metadata":{"id":"24Kv63BWOwqe"},"source":["import pandas\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import scipy\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (15,12)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tkhjGwmGOyB-"},"source":["#Data\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","names = ['preg','plas','pres','skin','test','mass','pedi','age','class']\n","data = pandas.read_csv(url, names=names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O30iDNuPOoZQ"},"source":["# Take a peek at your raw data.\n","data.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oSrLuecQ97C"},"source":["# Review the dimensions of your dataset.\n","data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EoCXgdY7RA8H"},"source":["# Review the data types of attributes in your data.\n","data.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MCgpzOhQRdHM"},"source":["## Descriptive Statistics"]},{"cell_type":"code","metadata":{"id":"lkO4zz1b2oc_"},"source":["data.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnXLTnAiRCre"},"source":["# Summarize the distribution of instances across classes in your dataset.\n","data.describe(include=\"all\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNKqyP9E6NuJ"},"source":["# mean\n","data[\"age\"].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gic8VCe_6Tvq"},"source":["# std\n","data[\"age\"].std()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFa3uaa36Ts2"},"source":["# variance\n","data[\"age\"].var()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EGkoD_lZ6Tp3"},"source":["# mode\n","data[\"age\"].mode()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aiK2gXtJ6TnD"},"source":["# median\n","data[\"age\"].median()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r4KrXJMH6TkB"},"source":["# interquartile range (IQR)\n","from scipy.stats import iqr\n","iqr(data[\"age\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rINKA1xJZMHi"},"source":["# 10th percentile\n","data[\"age\"].quantile(0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_lrq-aRxnPdT"},"source":["# 50th percentile same as median\n","data[\"age\"].quantile(0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"POf3_f__nPpm"},"source":["# 90th percentile\n","data[\"age\"].quantile(0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TC0yBBfGRD41"},"source":["# Class Distribution \n","data.groupby('class').size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NbiawuWERH02"},"source":["# Histograms\n","data.hist(bins=20) # adjust bin, range \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_tn7xwLRJvo"},"source":["# Density distribution\n","data.plot(kind= 'density' , subplots=True, layout=(3,3), sharex=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XdaGzJ6nY8LQ"},"source":["# Box plot\n","# Box plot with points representing data that extend beyond the whiskers (outliers)\n","data.plot(kind= 'box' , subplots=True, layout=(3,3), sharex=False, sharey=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpGw9eDxRTMT"},"source":["# don't show outliers\n","data.plot(kind= 'box' , subplots=True, layout=(3,3), sharex=False, sharey=False, showfliers=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1zPq2jnnmwa"},"source":["# X% Truncated (Trimmed) Mean\n","# x% of observations from each end are removed before the mean is computed\n","from scipy import stats\n","# scipy.stats.trim_mean(a, proportiontocut, axis=0)[source]\n","# If proportiontocut = 0.1, slices off ‘leftmost’ and ‘rightmost’ 10% of scores.\n","stats.trim_mean(data[\"age\"], 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VJ7OpGen6Ll"},"source":["# X% Winsorized Mean\n","# x% of observations from each end are replaced with the most extreme remaining values (on both ends) before the mean is computed\n","\n","# https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.mstats.winsorize.html\n","\n","age = data[\"age\"]\n","age.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dEq5LZE9EHhH"},"source":["# The 10% of the lowest value and the 20% of the highest\n","stats.mstats.winsorize(age, limits=[0.1, 0.2], inplace=True)\n","age.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g_TPgz5lV5JI"},"source":["# Part2: Inferential Statistics\n"]},{"cell_type":"code","metadata":{"id":"vm6uQ3gxohKJ"},"source":["import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","np.random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UrNfQOPrmaF"},"source":["coffee_full = pd.read_csv('https://github.com/devanshmalik/Inferential-Stats-in-Python/raw/master/confidence%20intervals%20%26%20hypothesis%20testing/coffee_dataset.csv')\n","print(coffee_full.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7QY8RVtFer8b"},"source":["coffee_full.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"94En1WZEer6g"},"source":["# population\n","coffee_full[\"drinks_coffee\"].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bZWIz2h4fHgw"},"source":["# sample1\n","coffee_sample = coffee_full.sample(200)\n","coffee_sample[\"drinks_coffee\"].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JGO7gw4fHeS"},"source":["# sample2\n","coffee_sample = coffee_full.sample(200)\n","coffee_sample[\"drinks_coffee\"].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMlKVfS6gBRx"},"source":["# sample3\n","coffee_sample = coffee_full.sample(200)\n","coffee_sample[\"drinks_coffee\"].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yyn6S5X0gBPW"},"source":["# central limit theorem; is it normal distribution?\n","# population mean = 0.589778076664425\n","sample_means = []\n","for _ in range(10000):\n","  coffee_sample = coffee_full.sample(200)\n","  m = coffee_sample[\"drinks_coffee\"].mean()\n","  sample_means.append(m)\n","    \n","plt.hist(sample_means, bins=30)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C7sqCt9LgREw"},"source":["# confidence interval\n","# population mean = 0.589778076664425\n","\n","def mean_confidence_interval(data, confidence=0.95):\n","  a = 1.0 * np.array(data)\n","  n = len(a)\n","  m = np.mean(a) \n","  se = scipy.stats.sem(a)\n","  h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n","  return m, h, m-h, m+h\n","\n","coffee_sample = coffee_full.sample(200)\n","data = coffee_sample[\"drinks_coffee\"]\n","m, bound, lower1, upper1 = mean_confidence_interval(data)\n","print(m, lower1, upper1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swwFNq0ciF1W"},"source":["# confidence interval with function\n","import numpy as np, scipy.stats as st\n","st.t.interval(0.95, len(data)-1, loc=np.mean(data), scale=st.sem(data))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nDw5YpTI9J5r"},"source":["## Central Limit Theorem (optional)\n","\n","\n","*   Vary number of samplings\n","*   Vary sampling size\n","\n"]},{"cell_type":"code","metadata":{"id":"Ar3ldAzS9LYR"},"source":["#---------------------------------------\n","# Generate simulated data from Gamma distribution\n","#---------------------------------------\n","\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","import scipy.stats as stats\n","%matplotlib inline\n","\n","## Central limit theorom\n","# build gamma distribution as population\n","shape, scale = 2., 2.  # mean=4, std=2*sqrt(2)\n","s = np.random.gamma(shape, scale, 1000000)\n","# plot\n","plt.figure(figsize=(20,10))\n","plt.hist(s, 200, density=True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Stqcojqc9LVi"},"source":["#---------------------------------------\n","# PART1: fixed sample size = 500 & vary the number samplings\n","#---------------------------------------\n","\n","# sample from population with different number of sampling\n","# a list of sample mean\n","meansample = []\n","# number of sample\n","numofsample = [1000,2500,5000,10000,25000,50000]\n","# sample size\n","samplesize = 500\n","# for each number of sampling (1000 to 50000)\n","for i in numofsample:\n","    # collect mean of each sample\n","    eachmeansample = []\n","    # for each sampling\n","    for j in range(0,i):\n","        # sampling 500 sample from population\n","        rc = random.choices(s, k=samplesize)\n","        # collect mean of each sample\n","        eachmeansample.append(sum(rc)/len(rc))\n","    # add mean of each sampling to the list\n","    meansample.append(eachmeansample)\n","    \n","# plot\n","cols = 2\n","rows = 3\n","fig, ax = plt.subplots(rows, cols, figsize=(20,15))\n","n = 0\n","for i in range(0, rows):\n","    for j in range(0, cols):\n","        ax[i, j].hist(meansample[n], 200, density=True)\n","        ax[i, j].set_title(label=\"number of sampling :\" + str(numofsample[n]))\n","        n += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcPz_RXW9LTd"},"source":["#---------------------------------------\n","# PART1 (cont.): fixed sample size = 500 & vary the number samplings\n","# convert to z-score\n","#---------------------------------------\n","# use last sampling\n","sm = meansample[len(meansample)-1]\n","# calculate start deviation\n","std = np.std(sm)\n","# set population mean\n","mean = np.mean(sm)\n","# list of standarded sample\n","zn = []\n","# for each sample subtract with mean and devided by standard deviation\n","for i in sm:\n","    zn.append((i-mean)/std)\n","    \n","# plot hist\n","plt.figure(figsize=(20,10))\n","plt.hist(zn, 200, density=True)\n","# compare with standard normal disrtibution line\n","mu = 0\n","sigma = 1\n","x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n","# draw standard normal disrtibution line\n","plt.plot(x, stats.norm.pdf(x, mu, sigma),linewidth = 5, color='red')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhNZTN7f9LPV"},"source":["#---------------------------------------\n","# PART2: vary the number of sampling sizes & the number samplings = 500 times\n","#---------------------------------------\n","## sample with different sample size\n","# list of sample mean\n","meansample = []\n","# number of sampling\n","numofsample = 25000\n","# sample size\n","samplesize = [1,5,10,30,100,1000]\n","# for each sample size (1 to 1000)\n","for i in samplesize:\n","    # collect mean of each sample\n","    eachmeansample = []\n","    # for each sampling\n","    for j in range(0,numofsample):\n","        # sampling i sample from population\n","        rc = random.choices(s, k=i)\n","        # collect mean of each sample\n","        eachmeansample.append(sum(rc)/len(rc))\n","    # add mean of each sampling to the list\n","    meansample.append(eachmeansample)\n","    \n","# plot\n","cols = 2\n","rows = 3\n","fig, ax = plt.subplots(rows, cols, figsize=(20,15))\n","n = 0\n","for i in range(0, rows):\n","    for j in range(0, cols):\n","        ax[i, j].hist(meansample[n], 200, density=True)\n","        ax[i, j].set_title(label=\"sample size :\" + str(samplesize[n]))\n","        n += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYczmp5i9Wkk"},"source":["#---------------------------------------\n","# PART2 (cont.): vary the number of sampling sizes & the number samplings = 500 times\n","# With sample size = 1000 - check all the values\n","#---------------------------------------\n","\n","## expect value of sample\n","# use last sampling (samplesize=1000)\n","sample = meansample[len(meansample)-1]\n","\n","# expected value of sample equal to expect value of population\n","print(\"expected value of sample:\", np.mean(sample))\n","print(\"expected value of population:\", shape*scale)\n","print()\n","\n","# standard deviation of sample equal to standard deviation of population divided by squre root of n\n","print(\"standard deviation of sample:\", np.std(sample))\n","print(\"standard deviation of population:\", scale*np.sqrt(shape))\n","print(\"standard deviation of population divided by squre root of sample size:\", scale*np.sqrt(shape)/np.sqrt(1000))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qoK-gn0h9Wai"},"source":["#---------------------------------------\n","# PART3: increase sample size can reduce error\n","#---------------------------------------\n","\n","## show that as the sample size increases the mean of sample is close to population mean\n","# set expected values of population\n","mu = shape*scale # mean\n","# sample size\n","samplesize = []\n","# collect difference between sample mean and mu\n","diflist = []\n","# for each sample size\n","for n in range(10,20000,20): \n","    # sample 10000 sample\n","    rs = random.choices(s, k=n)\n","    # start count\n","    c = 0\n","    # calculate mean\n","    mean = sum(rs)/len(rs)\n","    # collect difference between sample mean and mu\n","    diflist.append(mean-mu)\n","    samplesize.append(n)\n","\n","# set figure size.\n","plt.figure(figsize=(20,10))\n","# plot each diference.\n","plt.scatter(samplesize,diflist, marker='o')\n","# show plot.\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLAI0yT09Whz"},"source":["#---------------------------------------\n","# PART4: vary sample size\n","# for each sample size, trial 100 times\n","# count #error > 0.05\n","# Increase sample size can reduce prob of errors\n","#---------------------------------------\n","\n","## show that as the sample size increases the probability that sample mean is further from population mean than error\n","# margin of error\n","epsilon = 0.05\n","# list of probability of each sample size\n","proberror = []\n","# sample size for plotting\n","samplesize = []\n","\n","# for each sample size\n","for n in range(100,10101,500): \n","    # start count\n","    c = 0\n","    for i in range(0,100):\n","        # sample 10000 sample\n","        rs = random.choices(s, k=n)\n","        # calculate mean\n","        mean = sum(rs)/len(rs)\n","        # check if the difference is larger than error\n","        if abs(mean - mu) > epsilon:\n","            # if larger count the sampling\n","            c += 1\n","    # calculate the probability\n","    proberror.append(c/100)\n","    # save sample size for plotting\n","    samplesize.append(n)\n","\n","# set figure size.\n","plt.figure(figsize=(20,10))\n","# plot each probability.\n","plt.plot(samplesize,proberror, marker='o')\n","# show plot.\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r5PKqh2A9Nxm"},"source":["# Part3: A/B Testing"]},{"cell_type":"markdown","metadata":{"id":"zTybNCz7f6pp"},"source":["## One sample t-test: \n","\n","You have 10 ages and you are checking whether avg age is 30 or not. (check code below for that using python)"]},{"cell_type":"code","metadata":{"id":"NK6Pk1Ppj_6V"},"source":["mylist = [32,34,29,29,22,39,38,37,38,36,30,26,22,22]\n","df = pandas.DataFrame(data=mylist)\n","df.to_csv(\"ages.csv\", sep=',',index=False,header=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NdK6h05akiU3"},"source":["!head ages.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-m1agYoRlSA"},"source":["from scipy.stats import ttest_1samp\n","import numpy as np\n","ages = np.genfromtxt('ages.csv')\n","print(ages)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Crpha2zokdaW"},"source":["ages_mean = np.mean(ages)\n","print(ages_mean)\n","t, pval = ttest_1samp(ages, 30) # Calculate the T-test for the mean of ONE group of scores.\n","print(\"t =\", t, \", p-value =\", pval)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ei9iVOuflQfh"},"source":["if pval < 0.05:    # alpha value is 0.05 or 5%\n","   print(\"we are rejecting null hypothesis\")\n","else:\n","  print(\"we are accepting null hypothesis\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"spNITaKwlg-y"},"source":["## Two sample t-test: \n","\n","## Example: is there any association between week1 and week2 ( code is given below in python)"]},{"cell_type":"code","metadata":{"id":"Ua03yz_7mAQx"},"source":["import numpy as np\n","np.random.seed(2019) #option for reproducibility\n","week1_list = np.random.randint(low=0, high=100, size=50).tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HmDCh14jmFJI"},"source":["np.random.seed(2020) #option for reproducibility\n","week2_list = np.random.randint(low=0, high=100, size=50).tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"28XhM-aOlU0u"},"source":["df = pandas.DataFrame(data=week1_list)\n","df.to_csv(\"week1.csv\", sep=',',index=False,header=None)\n","df = pandas.DataFrame(data=week2_list)\n","df.to_csv(\"week2.csv\", sep=',',index=False,header=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxSbt1rimZu1"},"source":["from scipy.stats import ttest_ind\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SjRvO_eqmdnV"},"source":["week1 = np.genfromtxt(\"week1.csv\",  delimiter=\",\")\n","week2 = np.genfromtxt(\"week2.csv\",  delimiter=\",\")\n","print(\"week1 data :-\\n\")\n","print(week1)\n","print(\"\\n\")\n","print(\"week2 data :-\\n\")\n","print(week2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKdszGa52fKI"},"source":["import scipy.stats\n","# https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.levene.html\n","stats.levene(week1,week2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JfQhLj6tmgpK"},"source":["week1_mean = np.mean(week1)\n","week2_mean = np.mean(week2)\n","print(\"week1 mean value:\",week1_mean)\n","print(\"week2 mean value:\",week2_mean)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLY8xHaZmsZ5"},"source":["week1_std = np.std(week1)\n","week2_std = np.std(week2)\n","print(\"week1 std value:\",week1_std)\n","print(\"week2 std value:\",week2_std)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HBiBOuhumuSq"},"source":["ttest,pval = ttest_ind(week1,week2,equal_var=True) #  two independent samples of scores.\n","# ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n","print(\"p-value\",pval)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kzoBBKGjmwT6"},"source":["if pval <0.05:\n","  print(\"we reject null hypothesis\")\n","else:\n","  print(\"we accept null hypothesis\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G-ZEYd0xm6Ws"},"source":["## Paired t-test\n","\n","H0 :- mean difference between two sample is 0\n","\n","H1:- mean difference between two sample is not 0\n","\n","check the code below for same"]},{"cell_type":"code","metadata":{"id":"rDSYt2G8mytK"},"source":["import pandas as pd\n","from scipy import stats\n","from statsmodels.stats import weightstats as stests"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Akcg2e-3nEqX"},"source":["df = pd.read_csv(\"https://github.com/yug95/MachineLearning/raw/master/Hypothesis%20testing/blood_pressure.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yn2toi27oV6c"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAUFYKTFoYiZ"},"source":["df[['bp_before','bp_after']].describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZF45KNfoZVi"},"source":["ttest,pval = stats.ttest_rel(df['bp_before'], df['bp_after']) # return t-statistic and p-value\n","print(pval)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W6vcGg1nocdh"},"source":["if pval<0.05:\n","    print(\"reject null hypothesis\")\n","else:\n","    print(\"accept null hypothesis\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iy7NX7Ds7Pbu"},"source":["# Reference:\n","1. https://reneshbedre.github.io/blog/anova.html\n","2. https://medium.com/analytics-vidhya/illustration-with-python-central-limit-theorem-aa4d81f7b570"]},{"cell_type":"code","metadata":{"id":"Mp8Boy3WBM4m"},"source":[""],"execution_count":null,"outputs":[]}]}