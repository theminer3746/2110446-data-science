{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_StockPrice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a0KPOPJtu_S"
      },
      "source": [
        "New York Stock Exchange stock price prediction using LSTM\n",
        "\n",
        "Use S&P 500 companies historical prices to predict future prices\n",
        "\n",
        "![alt text](https://farm4.staticflickr.com/3835/14313202637_0cc6ec8649_z_d.jpg)\n",
        "\n",
        "Reference:https://www.kaggle.com/dgawlik/nyse/home\n",
        "\n",
        "This dataset is a playground for fundamental and technical analysis. It is said that 30% of traffic on stocks is already generated by machines, can trading be fully automated? If not, there is still a lot to learn from historical data.\n",
        "\n",
        "Most of data spans from 2010 to the end 2016, for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Iv2AY56Swn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d14328-1fd9-477a-eeff-8abd3e64e9d3"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/davidjohnnn/econ/master/prices-split-adjusted.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-23 00:11:11--  https://raw.githubusercontent.com/davidjohnnn/econ/master/prices-split-adjusted.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52701226 (50M) [text/plain]\n",
            "Saving to: ‘prices-split-adjusted.csv’\n",
            "\n",
            "prices-split-adjust 100%[===================>]  50.26M   227MB/s    in 0.2s    \n",
            "\n",
            "2021-03-23 00:11:12 (227 MB/s) - ‘prices-split-adjusted.csv’ saved [52701226/52701226]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swp7Xt75Vte8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4548df83-c143-4652-a763-77a51081e02d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prices-split-adjusted.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLGv7PEHN0Ig"
      },
      "source": [
        "# Setup\n",
        "import libraries needed for this application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNhH1lMX0-jq",
        "outputId": "7125f3a6-d932-4b2a-ab80-7b1beddf07e5"
      },
      "source": [
        "!pip3 install --upgrade keras==2.1.3\n",
        "!pip3 install --upgrade tensorflow==1.13.2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/ae/7f94a03cb3f74cdc8a0f5f86d1df5c1dd686acb9a9c2a421c64f8497358e/Keras-2.1.3-py2.py3-none-any.whl (319kB)\n",
            "\r\u001b[K     |█                               | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 20.2MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61kB 21.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 71kB 19.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 81kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 102kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 112kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 122kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 133kB 17.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 143kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 153kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 163kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 174kB 17.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 184kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 194kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 204kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 215kB 17.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 225kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 235kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 245kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 256kB 17.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 266kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 276kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 286kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 296kB 17.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 307kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 317kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 327kB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.3) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.3) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.3) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.3) (3.13)\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.1.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.1.3\n",
            "Collecting tensorflow==1.13.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/70/45d3b9fab768215a2055c7819d39547a4b0b7401b4583094068741aff99b/tensorflow-1.13.2-cp37-cp37m-manylinux1_x86_64.whl (92.7MB)\n",
            "\u001b[K     |████████████████████████████████| 92.7MB 88kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (3.12.4)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.19.5)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (54.1.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (2.10.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.7.2)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.4.1)\n",
            "Installing collected packages: tensorboard, keras-applications, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.2 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBvORAQ27MGF"
      },
      "source": [
        "datapath = 'prices-split-adjusted.csv' #or locate in google drive"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqjL7z3eH75v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75859fed-d33a-478e-d350-372039b2fd9d"
      },
      "source": [
        "#import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import itertools\n",
        "from sklearn import preprocessing\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.recurrent import LSTM\n",
        "import keras\n",
        "import matplotlib.pyplot as plt2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12I7q96ySLac"
      },
      "source": [
        "# Read data\n",
        "\n",
        "![alt text](https://cdn.pixabay.com/photo/2017/09/01/05/49/reading-2703163_1280.jpg)\n",
        "\n",
        "#### Let's read the CSV file and find out what does it look like?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxhQMsx8TiwQ"
      },
      "source": [
        "The first 5 rows of this dataset contains the value of WLTM  during 5 Jan 2016 - 11 Jan 2016.  It contains stock prices of other companies in NYSE as well.\n",
        "\n",
        "WLTW - Willis Towers Watson is a global multinational risk management, insurance brokerage and advisory company. The firm has roots dating to 1828 and is the third largest insurance broker in the world.  \n",
        "\n",
        "\n",
        "![alt text](https://pbs.twimg.com/profile_images/1017751865432387584/aionGfv8_400x400.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfmwq_PnH75z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "2a09faf8-b98c-4ac3-a66d-eaaa8a590403"
      },
      "source": [
        "# datapath =\"/content/stock/prices-split-adjusted.csv\"\n",
        "df = pd.read_csv(datapath, index_col = 0)\n",
        "df[\"mv close\"] = df.close\n",
        "df.drop(['volume','close'], 1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-05</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>125.839996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-06</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>119.980003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-07</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>114.949997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-08</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>116.620003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-11</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>114.970001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           symbol        open         low        high    mv close\n",
              "date                                                             \n",
              "2016-01-05   WLTW  123.430000  122.309998  126.250000  125.839996\n",
              "2016-01-06   WLTW  125.239998  119.940002  125.540001  119.980003\n",
              "2016-01-07   WLTW  116.379997  114.930000  119.739998  114.949997\n",
              "2016-01-08   WLTW  115.480003  113.500000  117.440002  116.620003\n",
              "2016-01-11   WLTW  117.010002  114.089996  117.330002  114.970001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KInBtx_AUfvt"
      },
      "source": [
        "### Statistical Summary of this dataset\n",
        "\n",
        "*   count = number of rows in the dataset\n",
        "*   mean  = average opening/low/high/closing  price\n",
        "*   std = standard deviation\n",
        "*   min = min. opening/low/high/closing  price\n",
        "*   price at 25%/50%/75% percentile\n",
        "*   max = max. opening/low/high/closing  price\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV-xZLaySgEe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "297e9728-de3c-4f00-c909-b6700ce8b8f6"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>851264.000000</td>\n",
              "      <td>851264.000000</td>\n",
              "      <td>851264.000000</td>\n",
              "      <td>851264.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>64.993618</td>\n",
              "      <td>64.336541</td>\n",
              "      <td>65.639748</td>\n",
              "      <td>65.011913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>75.203893</td>\n",
              "      <td>74.459518</td>\n",
              "      <td>75.906861</td>\n",
              "      <td>75.201216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.660000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.810000</td>\n",
              "      <td>1.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>31.270000</td>\n",
              "      <td>30.940001</td>\n",
              "      <td>31.620001</td>\n",
              "      <td>31.292776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>48.459999</td>\n",
              "      <td>47.970001</td>\n",
              "      <td>48.959999</td>\n",
              "      <td>48.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>75.120003</td>\n",
              "      <td>74.400002</td>\n",
              "      <td>75.849998</td>\n",
              "      <td>75.139999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1584.439941</td>\n",
              "      <td>1549.939941</td>\n",
              "      <td>1600.930054</td>\n",
              "      <td>1578.130005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                open            low           high       mv close\n",
              "count  851264.000000  851264.000000  851264.000000  851264.000000\n",
              "mean       64.993618      64.336541      65.639748      65.011913\n",
              "std        75.203893      74.459518      75.906861      75.201216\n",
              "min         1.660000       1.500000       1.810000       1.590000\n",
              "25%        31.270000      30.940001      31.620001      31.292776\n",
              "50%        48.459999      47.970001      48.959999      48.480000\n",
              "75%        75.120003      74.400002      75.849998      75.139999\n",
              "max      1584.439941    1549.939941    1600.930054    1578.130005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUPSU9PAXZxg"
      },
      "source": [
        "There are over 500 companies in this dataset including  Google, IBM, CBS Corporation, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv7HzTGLH754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38ac592-2649-4abf-b1b5-4d2f8400870e"
      },
      "source": [
        "#Symbol dimension\n",
        "symbols = list(set(df.symbol))\n",
        "print(\"Here are the list of companies in NYSE\")\n",
        "print(sorted(symbols))\n",
        "print(\"There are \" + str(len(symbols)) + \" companies in NYSE\" )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the list of companies in NYSE\n",
            "['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADS', 'ADSK', 'AEE', 'AEP', 'AES', 'AET', 'AFL', 'AGN', 'AIG', 'AIV', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALK', 'ALL', 'ALLE', 'ALXN', 'AMAT', 'AME', 'AMG', 'AMGN', 'AMP', 'AMT', 'AMZN', 'AN', 'ANTM', 'AON', 'APA', 'APC', 'APD', 'APH', 'ARNC', 'ATVI', 'AVB', 'AVGO', 'AVY', 'AWK', 'AXP', 'AYI', 'AZO', 'BA', 'BAC', 'BAX', 'BBBY', 'BBT', 'BBY', 'BCR', 'BDX', 'BEN', 'BHI', 'BIIB', 'BK', 'BLK', 'BLL', 'BMY', 'BSX', 'BWA', 'BXP', 'C', 'CA', 'CAG', 'CAH', 'CAT', 'CB', 'CBG', 'CBS', 'CCI', 'CCL', 'CELG', 'CERN', 'CF', 'CFG', 'CHD', 'CHK', 'CHRW', 'CHTR', 'CI', 'CINF', 'CL', 'CLX', 'CMA', 'CMCSA', 'CME', 'CMG', 'CMI', 'CMS', 'CNC', 'CNP', 'COF', 'COG', 'COH', 'COL', 'COO', 'COP', 'COST', 'COTY', 'CPB', 'CRM', 'CSCO', 'CSRA', 'CSX', 'CTAS', 'CTL', 'CTSH', 'CTXS', 'CVS', 'CVX', 'CXO', 'D', 'DAL', 'DD', 'DE', 'DFS', 'DG', 'DGX', 'DHI', 'DHR', 'DIS', 'DISCA', 'DISCK', 'DLPH', 'DLR', 'DLTR', 'DNB', 'DOV', 'DOW', 'DPS', 'DRI', 'DTE', 'DUK', 'DVA', 'DVN', 'EA', 'EBAY', 'ECL', 'ED', 'EFX', 'EIX', 'EL', 'EMN', 'EMR', 'ENDP', 'EOG', 'EQIX', 'EQR', 'EQT', 'ES', 'ESRX', 'ESS', 'ETFC', 'ETN', 'ETR', 'EVHC', 'EW', 'EXC', 'EXPD', 'EXPE', 'EXR', 'F', 'FAST', 'FB', 'FBHS', 'FCX', 'FDX', 'FE', 'FFIV', 'FIS', 'FISV', 'FITB', 'FL', 'FLIR', 'FLR', 'FLS', 'FMC', 'FOX', 'FOXA', 'FRT', 'FSLR', 'FTI', 'FTR', 'FTV', 'GD', 'GE', 'GGP', 'GILD', 'GIS', 'GLW', 'GM', 'GOOG', 'GOOGL', 'GPC', 'GPN', 'GPS', 'GRMN', 'GS', 'GT', 'GWW', 'HAL', 'HAR', 'HAS', 'HBAN', 'HBI', 'HCA', 'HCN', 'HCP', 'HD', 'HES', 'HIG', 'HOG', 'HOLX', 'HON', 'HP', 'HPE', 'HPQ', 'HRB', 'HRL', 'HRS', 'HSIC', 'HST', 'HSY', 'HUM', 'IBM', 'ICE', 'IDXX', 'IFF', 'ILMN', 'INTC', 'INTU', 'IP', 'IPG', 'IR', 'IRM', 'ISRG', 'ITW', 'IVZ', 'JBHT', 'JCI', 'JEC', 'JNJ', 'JNPR', 'JPM', 'JWN', 'K', 'KEY', 'KHC', 'KIM', 'KLAC', 'KMB', 'KMI', 'KMX', 'KO', 'KORS', 'KR', 'KSS', 'KSU', 'L', 'LB', 'LEG', 'LEN', 'LH', 'LKQ', 'LLL', 'LLTC', 'LLY', 'LMT', 'LNC', 'LNT', 'LOW', 'LRCX', 'LUK', 'LUV', 'LVLT', 'LYB', 'M', 'MA', 'MAA', 'MAC', 'MAR', 'MAS', 'MAT', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET', 'MHK', 'MJN', 'MKC', 'MLM', 'MMC', 'MMM', 'MNK', 'MNST', 'MO', 'MON', 'MOS', 'MPC', 'MRK', 'MRO', 'MSFT', 'MSI', 'MTB', 'MTD', 'MU', 'MUR', 'MYL', 'NAVI', 'NBL', 'NDAQ', 'NEE', 'NEM', 'NFLX', 'NFX', 'NI', 'NKE', 'NLSN', 'NOC', 'NOV', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NWL', 'NWS', 'NWSA', 'O', 'OKE', 'OMC', 'ORCL', 'ORLY', 'OXY', 'PAYX', 'PBCT', 'PBI', 'PCAR', 'PCG', 'PCLN', 'PDCO', 'PEG', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH', 'PHM', 'PKI', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'PPG', 'PPL', 'PRGO', 'PRU', 'PSA', 'PSX', 'PVH', 'PWR', 'PX', 'PXD', 'PYPL', 'QCOM', 'QRVO', 'R', 'RAI', 'RCL', 'REGN', 'RF', 'RHI', 'RHT', 'RIG', 'RL', 'ROK', 'ROP', 'ROST', 'RRC', 'RSG', 'RTN', 'SBUX', 'SCG', 'SCHW', 'SE', 'SEE', 'SHW', 'SIG', 'SJM', 'SLB', 'SLG', 'SNA', 'SNI', 'SO', 'SPG', 'SPGI', 'SPLS', 'SRCL', 'SRE', 'STI', 'STT', 'STX', 'STZ', 'SWK', 'SWKS', 'SWN', 'SYF', 'SYK', 'SYMC', 'SYY', 'T', 'TAP', 'TDC', 'TDG', 'TEL', 'TGNA', 'TGT', 'TIF', 'TJX', 'TMK', 'TMO', 'TRIP', 'TROW', 'TRV', 'TSCO', 'TSN', 'TSO', 'TSS', 'TWX', 'TXN', 'TXT', 'UAA', 'UAL', 'UDR', 'UHS', 'ULTA', 'UNH', 'UNM', 'UNP', 'UPS', 'URBN', 'URI', 'USB', 'UTX', 'V', 'VAR', 'VFC', 'VIAB', 'VLO', 'VMC', 'VNO', 'VRSK', 'VRSN', 'VRTX', 'VTR', 'VZ', 'WAT', 'WBA', 'WDC', 'WEC', 'WFC', 'WFM', 'WHR', 'WLTW', 'WM', 'WMB', 'WMT', 'WRK', 'WU', 'WY', 'WYN', 'WYNN', 'XEC', 'XEL', 'XL', 'XLNX', 'XOM', 'XRAY', 'XRX', 'XYL', 'YHOO', 'YUM', 'ZBH', 'ZION', 'ZTS']\n",
            "There are 501 companies in NYSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvKb4PKQX6sE"
      },
      "source": [
        "# Let's predict Google's stock price!\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/4/4a/Logo_2013_Google.png)\n",
        "* you can also replace \"GOOG\" with any company of your choice!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_XSkIvBH756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "47410522-c148-4aae-b220-6b27b73a372c"
      },
      "source": [
        "#Focus only 1 stock :GOOG\n",
        "SYM = 'GOOG'\n",
        "df = df[df.symbol == SYM]\n",
        "df.drop(['symbol'],1,inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>312.304948</td>\n",
              "      <td>310.955001</td>\n",
              "      <td>313.580158</td>\n",
              "      <td>312.205308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>312.419511</td>\n",
              "      <td>309.610028</td>\n",
              "      <td>312.748278</td>\n",
              "      <td>310.830459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>311.761979</td>\n",
              "      <td>302.048370</td>\n",
              "      <td>311.761979</td>\n",
              "      <td>302.994813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>303.562685</td>\n",
              "      <td>295.218951</td>\n",
              "      <td>303.861575</td>\n",
              "      <td>295.941242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>294.895159</td>\n",
              "      <td>293.455551</td>\n",
              "      <td>300.499172</td>\n",
              "      <td>299.886470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  open         low        high    mv close\n",
              "date                                                      \n",
              "2010-01-04  312.304948  310.955001  313.580158  312.205308\n",
              "2010-01-05  312.419511  309.610028  312.748278  310.830459\n",
              "2010-01-06  311.761979  302.048370  311.761979  302.994813\n",
              "2010-01-07  303.562685  295.218951  303.861575  295.941242\n",
              "2010-01-08  294.895159  293.455551  300.499172  299.886470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj8eRV09TlXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "e7136c2e-afe0-4545-89ce-c5f4440bddc8"
      },
      "source": [
        "#Statistical Summary\n",
        "df.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1762.000000</td>\n",
              "      <td>1762.000000</td>\n",
              "      <td>1762.000000</td>\n",
              "      <td>1762.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>459.806530</td>\n",
              "      <td>455.659218</td>\n",
              "      <td>463.484281</td>\n",
              "      <td>459.617409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>174.026396</td>\n",
              "      <td>172.601608</td>\n",
              "      <td>175.232816</td>\n",
              "      <td>173.946191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>218.336998</td>\n",
              "      <td>216.005726</td>\n",
              "      <td>220.314587</td>\n",
              "      <td>217.221182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>298.255074</td>\n",
              "      <td>295.896412</td>\n",
              "      <td>300.824200</td>\n",
              "      <td>298.389573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>436.554429</td>\n",
              "      <td>434.103619</td>\n",
              "      <td>438.701390</td>\n",
              "      <td>436.711351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>578.422067</td>\n",
              "      <td>572.884750</td>\n",
              "      <td>581.870130</td>\n",
              "      <td>577.497020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>816.679993</td>\n",
              "      <td>805.140015</td>\n",
              "      <td>816.679993</td>\n",
              "      <td>813.109985</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              open          low         high     mv close\n",
              "count  1762.000000  1762.000000  1762.000000  1762.000000\n",
              "mean    459.806530   455.659218   463.484281   459.617409\n",
              "std     174.026396   172.601608   175.232816   173.946191\n",
              "min     218.336998   216.005726   220.314587   217.221182\n",
              "25%     298.255074   295.896412   300.824200   298.389573\n",
              "50%     436.554429   434.103619   438.701390   436.711351\n",
              "75%     578.422067   572.884750   581.870130   577.497020\n",
              "max     816.679993   805.140015   816.679993   813.109985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI7xkq09UGY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c9ca4b1-045f-4a92-900d-fe2713d1ec62"
      },
      "source": [
        "#Date data dimension\n",
        "import datetime \n",
        "\n",
        "print(df.index.min())\n",
        "print(df.index.max())\n",
        "delta = datetime.datetime.strptime(df.index.max(),'%Y-%m-%d')- datetime.datetime.strptime(df.index.min(),'%Y-%m-%d')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2010-01-04\n",
            "2016-12-30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BdpodyJTete"
      },
      "source": [
        "# Normalize data\n",
        "Normalization is a common process in machine learning. We do it to make sure that all features are using a common scale. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BifdUT7zH75-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "59c5c903-2837-4862-a295-d25068cdd55f"
      },
      "source": [
        "def normalize_data(df): # nomalize stock data\n",
        "    min_max_scaler = preprocessing.MinMaxScaler() #min max scaler\n",
        "    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
        "    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
        "    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
        "#    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1)) # already remove volume data\n",
        "    df['mv close'] = min_max_scaler.fit_transform(df['mv close'].values.reshape(-1,1))\n",
        "    return df\n",
        "df = normalize_data(df)\n",
        "df.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>0.157047</td>\n",
              "      <td>0.161167</td>\n",
              "      <td>0.156390</td>\n",
              "      <td>0.159399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>0.157238</td>\n",
              "      <td>0.158884</td>\n",
              "      <td>0.154995</td>\n",
              "      <td>0.157092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>0.156140</td>\n",
              "      <td>0.146049</td>\n",
              "      <td>0.153341</td>\n",
              "      <td>0.143942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>0.142436</td>\n",
              "      <td>0.134457</td>\n",
              "      <td>0.140094</td>\n",
              "      <td>0.132105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>0.127950</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.134455</td>\n",
              "      <td>0.138726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-11</th>\n",
              "      <td>0.138324</td>\n",
              "      <td>0.135632</td>\n",
              "      <td>0.135466</td>\n",
              "      <td>0.137965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-12</th>\n",
              "      <td>0.132654</td>\n",
              "      <td>0.130525</td>\n",
              "      <td>0.130204</td>\n",
              "      <td>0.129079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-13</th>\n",
              "      <td>0.115038</td>\n",
              "      <td>0.118603</td>\n",
              "      <td>0.122035</td>\n",
              "      <td>0.126245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-14</th>\n",
              "      <td>0.121207</td>\n",
              "      <td>0.126137</td>\n",
              "      <td>0.126896</td>\n",
              "      <td>0.128552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-15</th>\n",
              "      <td>0.129066</td>\n",
              "      <td>0.122104</td>\n",
              "      <td>0.126362</td>\n",
              "      <td>0.120318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                open       low      high  mv close\n",
              "date                                              \n",
              "2010-01-04  0.157047  0.161167  0.156390  0.159399\n",
              "2010-01-05  0.157238  0.158884  0.154995  0.157092\n",
              "2010-01-06  0.156140  0.146049  0.153341  0.143942\n",
              "2010-01-07  0.142436  0.134457  0.140094  0.132105\n",
              "2010-01-08  0.127950  0.131464  0.134455  0.138726\n",
              "2010-01-11  0.138324  0.135632  0.135466  0.137965\n",
              "2010-01-12  0.132654  0.130525  0.130204  0.129079\n",
              "2010-01-13  0.115038  0.118603  0.122035  0.126245\n",
              "2010-01-14  0.121207  0.126137  0.126896  0.128552\n",
              "2010-01-15  0.129066  0.122104  0.126362  0.120318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFmZ10qsCUV7"
      },
      "source": [
        "# Generate Data for LSTM\n",
        "![alt text](https://drive.google.com/uc?id=1SOT-t7z2qbfhzJnGmWMhJpz8JlB5V1kn)\n",
        "\n",
        "Predict the stock price based on the data from the previous 5 days"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3-hcDDBH76D"
      },
      "source": [
        "def load_data(stock, seq_len):   \n",
        "    n_features = len(stock.columns) #count columns of stock df 4 features open/low/high/close\n",
        "    data = stock.to_numpy()   #change to matrix numpy array\n",
        "    sequence_length = seq_len + 1 #5+1\n",
        "    result = []\n",
        "    \n",
        "    for index in range(len(data) - sequence_length): #1762 data but exclude sequence len , 0 to 1762-6 => 1756\n",
        "        result.append(data[index: index + sequence_length]) # construct table with 1756 2d arrays, each with [6,nfeature] (1756,6,4)\n",
        "    \n",
        "    result = np.array(result)\n",
        "    row = round(0.9 * result.shape[0]) # 90% of 1756 data\n",
        "    train = result[:int(row), :] # select first 90% as train data = 1580 data\n",
        "\n",
        "    x_train = train[:, :-1] #(1580,5,4) , x is previous 5 days data with 4 columns\n",
        "    y_train = train[:, -1][:,-1] #(1580), y is the close price of the sixth days\n",
        "    \n",
        "    x_test = result[int(row):, :-1]  # test is remaining rows 10% of data (176,5,4)\n",
        "    y_test = result[int(row):, -1][:,-1]#(176,)\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_features)) # reshape again (1580,5,4)\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_features))  \n",
        "\n",
        "    return [x_train, y_train, x_test, y_test]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0WnWP65H76H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9539ac-890d-4e85-dbd3-ed3dce7c5b2c"
      },
      "source": [
        "# set feature dimension and look back period\n",
        "n_features = 4\n",
        "prev_days = 5\n",
        "X_train, y_train, X_test, y_test = load_data(df, prev_days)\n",
        "print (X_train[0], y_train[0])\n",
        "print(X_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.15704696 0.16116746 0.15638998 0.15939908]\n",
            " [0.15723843 0.15888449 0.15499506 0.15709185]\n",
            " [0.15613951 0.14604929 0.15334121 0.14394234]\n",
            " [0.14243617 0.13445699 0.14009362 0.13210528]\n",
            " [0.12795029 0.13146379 0.13445546 0.13872603]] 0.1379653023031744\n",
            "(1580, 5, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq58-J-ECbEh"
      },
      "source": [
        "# Build LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSOFqQcd3q_g"
      },
      "source": [
        "**References **\n",
        "\n",
        "Return sequence:\n",
        "\n",
        "https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/\n",
        "https://stackoverflow.com/questions/42755820/how-to-use-return-sequences-option-and-timedistributed-layer-in-keras\n",
        "\n",
        "Reshape input for lstm\n",
        "\n",
        "https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n",
        "\n",
        "\n",
        "Stack LSTM\n",
        "\n",
        " https://machinelearningmastery.com/stacked-long-short-term-memory-networks/\n",
        " http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        " \n",
        "![](https://drive.google.com/uc?id=123aJD6phLzahdkhntLG2JL0A4IjCakDl)\n",
        " ![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/architecture_stacked_lstm.png)\n",
        " ![](http://adventuresinmachinelearning.com/wp-content/uploads/2018/01/Keras-LSTM-return-sequences-diagram-1024x275.png)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOUwcTJxH76N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da671126-94b6-46aa-f86e-cd7a0fc55171"
      },
      "source": [
        "def build_model(layers):\n",
        "    p = 0.2 #drop out 20%\n",
        "    model = Sequential() #sequential type\n",
        "\n",
        "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True)) # 5 previous days ,4 features\n",
        "    model.add(Dropout(p)) #dropout between layer\n",
        "\n",
        "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
        "    model.add(Dropout(p))\n",
        "\n",
        "    model.add(Dense(128,activation='relu'))\n",
        "    model.add(Dense(1,activation='linear'))\n",
        "\n",
        "    model.compile(loss='mse',optimizer='adam', metrics=['mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model([n_features, prev_days, 1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiNdO5cLCeZl"
      },
      "source": [
        "# Train LSTM model\n",
        "\n",
        "This is where your model learn from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3p7Q_CqH76R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f32dcf-bbfc-428c-f085-742e38519908"
      },
      "source": [
        "#setseed to produce same result\n",
        "from numpy.random import seed\n",
        "seed(5)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(20)\n",
        "\n",
        "# Checkpoint for call back function\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"/content/weights.best.hdf5\" #for print only best model\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "#validation split select 10% of data to validate (last 10% sequence)\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_split=0.1, verbose=1, callbacks =callbacks_list) \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 1422 samples, validate on 158 samples\n",
            "Epoch 1/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 00001: val_loss improved from inf to 0.00138, saving model to /content/weights.best.hdf5\n",
            "1422/1422 [==============================] - 4s 3ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
            "Epoch 2/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 7.6554e-04 - mean_squared_error: 7.6554e-04\n",
            "Epoch 00002: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 7.6753e-04 - mean_squared_error: 7.6753e-04 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 3/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 6.3746e-04 - mean_squared_error: 6.3746e-04\n",
            "Epoch 00003: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 6.3741e-04 - mean_squared_error: 6.3741e-04 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
            "Epoch 4/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 6.9300e-04 - mean_squared_error: 6.9300e-04\n",
            "Epoch 00004: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 6.8858e-04 - mean_squared_error: 6.8858e-04 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 5/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 7.5337e-04 - mean_squared_error: 7.5337e-04\n",
            "Epoch 00005: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 7.5545e-04 - mean_squared_error: 7.5545e-04 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 6/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 7.0773e-04 - mean_squared_error: 7.0773e-04\n",
            "Epoch 00006: val_loss improved from 0.00138 to 0.00117, saving model to /content/weights.best.hdf5\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 7.0279e-04 - mean_squared_error: 7.0279e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
            "Epoch 7/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 5.8559e-04 - mean_squared_error: 5.8559e-04\n",
            "Epoch 00007: val_loss improved from 0.00117 to 0.00083, saving model to /content/weights.best.hdf5\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 5.8524e-04 - mean_squared_error: 5.8524e-04 - val_loss: 8.3118e-04 - val_mean_squared_error: 8.3118e-04\n",
            "Epoch 8/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 6.0706e-04 - mean_squared_error: 6.0706e-04\n",
            "Epoch 00008: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 6.0259e-04 - mean_squared_error: 6.0259e-04 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
            "Epoch 9/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 7.0592e-04 - mean_squared_error: 7.0592e-04\n",
            "Epoch 00009: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 7.0157e-04 - mean_squared_error: 7.0157e-04 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 10/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 9.5446e-04 - mean_squared_error: 9.5446e-04\n",
            "Epoch 00010: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 9.7089e-04 - mean_squared_error: 9.7089e-04 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 11/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 8.5320e-04 - mean_squared_error: 8.5320e-04\n",
            "Epoch 00011: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 8.4821e-04 - mean_squared_error: 8.4821e-04 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
            "Epoch 12/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 5.3503e-04 - mean_squared_error: 5.3503e-04\n",
            "Epoch 00012: val_loss improved from 0.00083 to 0.00081, saving model to /content/weights.best.hdf5\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 5.3135e-04 - mean_squared_error: 5.3135e-04 - val_loss: 8.1357e-04 - val_mean_squared_error: 8.1357e-04\n",
            "Epoch 13/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 6.1802e-04 - mean_squared_error: 6.1802e-04\n",
            "Epoch 00013: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 6.1568e-04 - mean_squared_error: 6.1568e-04 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 14/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 5.8469e-04 - mean_squared_error: 5.8469e-04\n",
            "Epoch 00014: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 5.8120e-04 - mean_squared_error: 5.8120e-04 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 15/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 5.2561e-04 - mean_squared_error: 5.2561e-04\n",
            "Epoch 00015: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 5.4120e-04 - mean_squared_error: 5.4120e-04 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 16/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 5.6613e-04 - mean_squared_error: 5.6613e-04\n",
            "Epoch 00016: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 5.6551e-04 - mean_squared_error: 5.6551e-04 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
            "Epoch 17/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 5.2489e-04 - mean_squared_error: 5.2489e-04\n",
            "Epoch 00017: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 5.2551e-04 - mean_squared_error: 5.2551e-04 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 18/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 5.3533e-04 - mean_squared_error: 5.3533e-04\n",
            "Epoch 00018: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 5.3300e-04 - mean_squared_error: 5.3300e-04 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 19/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 4.6743e-04 - mean_squared_error: 4.6743e-04\n",
            "Epoch 00019: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 4.7694e-04 - mean_squared_error: 4.7694e-04 - val_loss: 9.7192e-04 - val_mean_squared_error: 9.7192e-04\n",
            "Epoch 20/20\n",
            "1408/1422 [============================>.] - ETA: 0s - loss: 4.8430e-04 - mean_squared_error: 4.8430e-04\n",
            "Epoch 00020: val_loss did not improve\n",
            "1422/1422 [==============================] - 3s 2ms/step - loss: 4.8605e-04 - mean_squared_error: 4.8605e-04 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9hRBQRhxzsI"
      },
      "source": [
        "#Load best model from check point\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mIHWQyTxzOW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f68b8f-e233-4e37-d02e-b347269b725e"
      },
      "source": [
        "# load weights\n",
        "print(filepath)\n",
        "model.load_weights(filepath)\n",
        "\n",
        "# Compile model (required to make predictions)\n",
        "model.compile(loss='mse',optimizer='adam', metrics=['mse'])\n",
        "print(\"Created model and loaded weights from file\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/weights.best.hdf5\n",
            "Created model and loaded weights from file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtmzADYzxyml"
      },
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISoe_EGYxxZf"
      },
      "source": [
        "diff=[]\n",
        "ratio=[]\n",
        "predict = model.predict(X_test)\n",
        "for d in range(len(y_test)):\n",
        "    pred = predict[d][0]\n",
        "    ratio.append((y_test[d]/pred)-1)\n",
        "    diff.append(abs(y_test[d] - pred))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6giLzdAxwmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41373bb-ba68-45cd-946f-c74ea6d159ad"
      },
      "source": [
        "print(predict.shape)\n",
        "print(ratio[0])\n",
        "print(diff[0])\n",
        "print(X_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(176, 1)\n",
            "0.01503310935054225\n",
            "0.013469070525159998\n",
            "(176, 5, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR98buG_E_oM"
      },
      "source": [
        "# Denomalize prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJUDVokCH76Y"
      },
      "source": [
        "df = pd.read_csv(datapath, index_col = 0)\n",
        "df[\"mv close\"] = df.close\n",
        "df.drop(['volume', 'close'], 1, inplace=True)\n",
        "df = df[df.symbol == SYM]\n",
        "df.drop(['symbol'],1,inplace=True)\n",
        "\n",
        "def denormalize(df, normalized_value): #\n",
        "    df = df['mv close'].values.reshape(-1,1)\n",
        "    normalized_value = normalized_value.reshape(-1,1)\n",
        "\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    _ = min_max_scaler.fit_transform(df)\n",
        "    denorm = min_max_scaler.inverse_transform(normalized_value)\n",
        "    return denorm\n",
        "\n",
        "new_pred = denormalize(df, predict)\n",
        "newy_test = denormalize(df, y_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzslJSYIhmKw",
        "outputId": "112b0ade-36fc-493f-e89a-5ba9ca01d752"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print(math.sqrt(mean_squared_error(newy_test, new_pred))) #RMSE\n",
        "print(newy_test.mean())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15.094728649983363\n",
            "752.340568215909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H7ae6xeFgay"
      },
      "source": [
        "# Apply trading model \n",
        "![alt text](https://i.kym-cdn.com/photos/images/original/001/008/446/514.jpg)\n",
        "\n",
        "Based on our prediction we use a set of simple rules to decide when to do transaction. (Can you come up with a better rule?)\n",
        "\n",
        "\n",
        "1.   Buy when you have ZERO volume **AND** when  the current price starts to go up (2% more than the previous day)\n",
        "2.   Sell when you have stocks  **AND** when the current price starts to go down (2% less than the previous day)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXTeHY-AH76h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "b636b041-b28c-4831-aa06-e330fe8bb796"
      },
      "source": [
        "init_balance = 100000.0\n",
        "balance = init_balance\n",
        "cash_list= []\n",
        "volume = 0\n",
        "buyx = []\n",
        "buyy =[]\n",
        "selx = []\n",
        "sely = []\n",
        "for i in range(1,len(new_pred)): # from first prediction\n",
        "    prediction= new_pred[i]\n",
        "    if(prediction > new_pred[i-1] * 1.002 and volume == 0): #if current > previous 0.2% and have not buy\n",
        "        volume = balance / newy_test[i] # buy with volume all balance/actual closing price\n",
        "        buyx.append(i) # save buy record index\n",
        "        buyy.append(newy_test[i])# save buy record price\n",
        "        print( \"Buy @\" + str(newy_test[i])) # print buy volume\n",
        "\n",
        "    if(volume > 0 and prediction * 1.002 < new_pred[i-1]): #check if have volume, and current < previous 0.2%\n",
        "        balance = volume * newy_test[i] #sell all volume\n",
        "        volume = 0\n",
        "        selx.append(i) #save record\n",
        "        sely.append(newy_test[i]) #save sell record\n",
        "        print (\"Sell @\" + str(newy_test[i])) #print sell price\n",
        "        print (\"Balance: \" + str(balance))# print balance\n",
        "\n",
        "print (\"Balance:\" + str(balance)) #print final balance\n",
        "print (\"Yield:\" + str((balance/init_balance-1)*100)+'%') #print final balance\n",
        "plt2.scatter(buyx, buyy, color='green',label ='buy')\n",
        "plt2.scatter(selx, sely, color='magenta', label ='sell')\n",
        "plt2.legend()\n",
        "plt2.grid(True)\n",
        "plt2.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buy @[712.900024]\n",
            "Sell @[706.630005]\n",
            "Balance: [99120.49112233]\n",
            "Buy @[724.119995]\n",
            "Sell @[716.650024]\n",
            "Balance: [98097.97109899]\n",
            "Buy @[694.950012]\n",
            "Sell @[772.080017]\n",
            "Balance: [108985.51246269]\n",
            "Buy @[775.320007]\n",
            "Sell @[759.690002]\n",
            "Balance: [106788.42727291]\n",
            "Buy @[776.219971]\n",
            "Sell @[783.609985]\n",
            "Balance: [107805.10811348]\n",
            "Buy @[762.559998]\n",
            "Sell @[758.48999]\n",
            "Balance: [107229.72040155]\n",
            "Buy @[769.200012]\n",
            "Sell @[750.5]\n",
            "Balance: [104622.85999205]\n",
            "Buy @[789.289978]\n",
            "Balance:[104622.85999205]\n",
            "Yield:[4.62285999]%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS8sEDlcONaO"
      },
      "source": [
        "# Final prediction performance with simulate trading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdYS3W4sH76o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "af055d19-2831-4c4a-b032-61b1717d5b07"
      },
      "source": [
        "plt2.plot(new_pred,color='red', label='Prediction')\n",
        "plt2.plot(newy_test,color='blue', label='Actual')\n",
        "plt2.scatter(buyx, buyy, color='green',label='buy')\n",
        "plt2.scatter(selx, sely, color='magenta',label='sell')\n",
        "plt2.legend(loc='best')\n",
        "plt2.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXccWoTJ07St"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}